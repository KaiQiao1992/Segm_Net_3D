{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-D Segmentation Network Toy Problem Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements the 3D Segmentation Network to a custom toy problem. Tho objective is to segmentate volumes of different shape within a big rectangular prism. The volumes to be segmented can have different intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# Enviroment reset\n",
    "%reset  \n",
    "# matplotlib plots within notebook\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "# Package importing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mayavi import mlab\n",
    "import pylab\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "\n",
    "# Custom packages\n",
    "import sys\n",
    "sys.path.insert(0, '../Librerias/Segm_Net_3D')\n",
    "\n",
    "import Geometrias_3D as geo3D\n",
    "import Segm_net_3D as segm3D\n",
    "\n",
    "# Tensor Flow\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to checkpoint\n",
    "CHECKPOINT_PATH = \"../Salidas/Segm_Net_3D_Full/Segm_Net_3D.ckpt\"\n",
    "\n",
    "# Path to tensorboard desiered output\n",
    "TENSORBOARD_TRAIN_PATH = \"../TensorGraph_out/Segm_Net_3D_Full/train\"\n",
    "TENSORBOARD_TEST_PATH = \"../TensorGraph_out/Segm_Net_3D_Full/test\"\n",
    "\n",
    "# --- Network parameters\n",
    "\n",
    "# Imput volume size\n",
    "voxels_X = 128\n",
    "voxels_Y = 128\n",
    "voxels_Z = 32\n",
    "input_size = (voxels_X,voxels_Y,voxels_Z)\n",
    "# Cube fileter size of convolution layers\n",
    "size_filt_fine = (3, 3, 3) \n",
    "# Cube fileter size of last output layer\n",
    "size_filt_out = (1, 1, 1) \n",
    "# Down-sample cube filter size\n",
    "size_filt_down = (2, 2, 2) \n",
    "# Up-mple clube filter size\n",
    "sizet_up = (2, 2, 2) \n",
    "# Imput channels, only one intensity volume\n",
    "input_size_1 = 1\n",
    "# Output channels, one per class plus background\n",
    "num_clases = 6+1\n",
    "# Volume color depth in this case is a single channel (intensity image)\n",
    "input_channels = 1\n",
    "# Network input placeholder\n",
    "ph_entry = tf.placeholder(tf.float32)\n",
    "# Network state placeholder (Train or Test)\n",
    "phase = tf.placeholder(tf.bool)\n",
    "# Depth of the network, hoy many down-convolutions will take place before the base level\n",
    "network_depth = 4\n",
    "# Channels to apply at each level in the down-ward path\n",
    "net_channels_down = [16, 32, 64, 128]\n",
    "# Channels to apply at base level\n",
    "net_channels_base = [256]\n",
    "# Channels to apply at each level in the up-ward path\n",
    "net_channels_up = [16, 32, 64, 128]\n",
    "# Channels to apply at segmentation/output level\n",
    "net_channels_segm = [1]\n",
    "# Convolutional layers to apply at each level in the down-ward path\n",
    "net_layers_down = [2, 2, 2, 2]\n",
    "# Convolutional layers to apply at base level\n",
    "net_layers_base = [2]\n",
    "# Convolutional layers to apply at each level in the up-ward path\n",
    "net_layers_up = [1, 2, 2, 2]\n",
    "\n",
    "# --- Trainer parameters\n",
    "\n",
    "# Volume mini-batch size\n",
    "batch_size = 3\n",
    "# Ground truth imput placeholder\n",
    "ph_truth = tf.placeholder(tf.float32, [batch_size, voxels_X, voxels_Y, voxels_Z, num_clases])\n",
    "# Train step size placeholder\n",
    "with tf.name_scope('step_size'):\n",
    "    step_size = tf.placeholder(tf.float32)\n",
    "    tf.summary.scalar('step_size', step_size)\n",
    "# Initial step size\n",
    "step_size_ini = 1e-3\n",
    "\n",
    "# --- Volume generation parameters\n",
    "\n",
    "# Noise to be added\n",
    "noise_max = 0.15;\n",
    "# Amount of elements to be inserted in the volume\n",
    "Elements_number = 10\n",
    "# Margins of volume to be left unpopulated\n",
    "margins = (12,12,12,12,2,2)\n",
    "# Size range of objects\n",
    "object_size_range = (3,12)\n",
    "# Transparency range of objects\n",
    "object_transp_range = (0.6,0.95)\n",
    "# Gauss filtering parameter\n",
    "gauss_sigma = 0.5\n",
    "# Class learned (0 for multi-class)\n",
    "class_learn = 0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network and Trainer assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Network assembly\n",
    "\n",
    "net_out = segm3D.Assemble_Network(ph_entry, phase, input_size, input_channels, num_clases, size_filt_fine, size_filt_out, network_depth, net_channels_down, net_layers_down, net_channels_base, net_layers_base, net_channels_up, net_layers_up, net_channels_segm)\n",
    "\n",
    "\n",
    "\n",
    "# Trainer assembly\n",
    "\n",
    "# Apply the dice loss, wich must be maximized\n",
    "with tf.name_scope('dice_loss'):\n",
    "    diff = segm3D.dice_loss(net_out, ph_truth)\n",
    "with tf.name_scope('total'):\n",
    "    maxim_objct = tf.reduce_mean(diff)\n",
    "tf.summary.scalar('dice_loss', maxim_objct)\n",
    "\n",
    "# Apply an ADAM optimizer wich minimizes the negated dice loss\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(step_size).minimize(-maxim_objct)\n",
    "    \n",
    "# Batch normalization mean and deviation updater\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Merge all the summaries and write them out to the specified path\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "train_writer = tf.summary.FileWriter(TENSORBOARD_TRAIN_PATH,\n",
    "                                      sess.graph)\n",
    "test_writer = tf.summary.FileWriter(TENSORBOARD_TEST_PATH)\n",
    "\n",
    "# Train the model and save it in the end\n",
    "model_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, diceloss: 0.0592543\n",
      "step 1000, diceloss: 0.620119\n",
      "step 2000, diceloss: 0.678825\n",
      "step 3000, diceloss: 0.711138\n",
      "step 4000, diceloss: 0.782142\n",
      "step 5000, diceloss: 0.812811\n",
      "step 6000, diceloss: 0.839637\n",
      "step 7000, diceloss: 0.858026\n",
      "step 8000, diceloss: 0.873125\n",
      "step 9000, diceloss: 0.889265\n",
      "step 10000, diceloss: 0.89984\n",
      "step 11000, diceloss: 0.912346\n",
      "step 12000, diceloss: 0.906259\n",
      "step 13000, diceloss: 0.931157\n",
      "step 14000, diceloss: 0.935945\n",
      "step 15000, diceloss: 0.941711\n",
      "step 16000, diceloss: 0.947603\n",
      "step 17000, diceloss: 0.951023\n",
      "step 18000, diceloss: 0.953619\n",
      "step 19000, diceloss: 0.955359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../Salidas/test/Segm_Net_3D.ckpt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Variable initialization\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "step_size_act = step_size_ini\n",
    "# Train Loop\n",
    "for i in range(0, 20000):\n",
    "    # Random mini batch generation\n",
    "    (batch_in, batch_label) = geo3D.fun_gen_batch(batch_size,\n",
    "                                               [voxels_X, voxels_Y, voxels_Z], \n",
    "                                               noise_max, \n",
    "                                               Elements_number, \n",
    "                                               margins, \n",
    "                                               object_size_range, \n",
    "                                               object_transp_range, \n",
    "                                               gauss_sigma,\n",
    "                                               class_learn)\n",
    "    # Cast ground truth to int32\n",
    "    batch_label = batch_label.astype(int)\n",
    "\n",
    "    # Every 100 iterations we test the model\n",
    "    if i%100 == 0:\n",
    "        summary, train_accuracy = sess.run([merged, maxim_objct], feed_dict={ph_entry:batch_in, ph_truth: batch_label, step_size: step_size_act, phase: False})\n",
    "        test_writer.add_summary(summary, i)\n",
    "        # Every 100 iterations we print the diceloss\n",
    "        if i%1000 == 0:\n",
    "            print(\"step %d, diceloss: %g\"%(i, train_accuracy))\n",
    "        \n",
    "        \n",
    "    # Train\n",
    "    summary, _, _ = sess.run([merged, train_step, extra_update_ops], feed_dict={ph_entry: batch_in, ph_truth: batch_label, step_size: step_size_act, phase: True})\n",
    "    train_writer.add_summary(summary, i)\n",
    "    \n",
    "    # Update train step\n",
    "    step_size_act = step_size_ini / np.sqrt(i+1)\n",
    "    \n",
    "\n",
    "# Save the trained network\n",
    "model_saver.save(sess, CHECKPOINT_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
